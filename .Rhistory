}
u <- ustar[(t+1),k]
uarray <- c(uarray,u)
}
uhat[dindex,t,ptindex] <- mean(uarray)
if (!sum(is.na(uhat[,t,ptindex]))==3){
dstar[t,ptindex] <- which.max(uhat[,t,ptindex])
ustar[t,ptindex] <- uhat[dstar[t,ptindex],t,ptindex]
}
}
}
}
View(dstar)
#Plot heatmap for estimated utilities
data <- expand.grid(t=1:Tmax, p=ptgrid)
data
data$dstar <- c(dstar)
data
#Plot heatmap for estimated utilities
data <- expand.grid(t=1:Tmax, p=ptgrid)
data$dstar <- c(dstar)
data$ustar <- c(ustar)
# Heatmap
ggplot(data, aes(t, p, fill= dstar)) +
geom_tile()
# Library
library(ggplot2)
# Heatmap
ggplot(data, aes(t, p, fill= dstar)) +
geom_tile()
?t.test()
# NOT RUN {
require(graphics)
t.test(1:10, y = c(7:20))      # P = .00001855
t.test(1:10, y = c(7:20, 200)) # P = .1245    -- NOT significant anymore
460-445
(460-445)/32*sqrt(13)
################ (6)
set.seed(702)
sample <- rnorm(20)
print(sample)
n <- 20
mu <- 0
alpha <- n/2
beta <- sum((sample-mu)^2)/2
cat(alpha,beta)
post <- function(s){
beta^alpha * s^(-alpha-1) * exp(-beta/s) / gamma(alpha)
}
xaxis <- seq(0.01,10000,by=0.001)
priorx <- 1/xaxis
priorx <- priorx/(sum(priorx)*0.001)
df <- data.frame(x=xaxis, y=priorx)
ggplot(data=df, aes(x=x, y=y, color="prior")) +
geom_line()+
geom_function(aes(color = "posterior"), fun = post, n=1000)+
scale_color_manual(name = "", values = c("prior" = "red", "posterior"="blue")) +
ylab("density") + xlim(0, 3)
library(ggplot2)
ggplot(data=df, aes(x=x, y=y, color="prior")) +
geom_line()+
geom_function(aes(color = "posterior"), fun = post, n=1000)+
scale_color_manual(name = "", values = c("prior" = "red", "posterior"="blue")) +
ylab("density") + xlim(0, 3)
nseq=100000
pseq <- seq(0.001,3,length.out=nseq)
postseq <- post(pseq)
seqstep <- pseq[2]-pseq[1]
for (i in 1:(nseq/2)){
if (sum(postseq[1:(i+1)])*seqstep >= 0.05){
ci1index <- i+1
ci1 <- pseq[(i+1)]
break
}
}
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[ci1index:ci2index])*seqstep,2))
nseq=100000
pseq <- seq(0.001,3,length.out=nseq)
postseq <- post(pseq)
seqstep <- pseq[2]-pseq[1]
for (i in 1:(nseq/2)){
if (sum(postseq[1:(i+1)])*seqstep >= 0.05){
ci1index <- i+1
ci1 <- pseq[(i+1)]
break
}
}
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep > 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[ci1index:ci2index])*seqstep,2))
# HPD
for (j in seq(0.0001,1.5,by=0.0001)){
index <- which(postseq>=j)
i1 <- index[1]
i2 <- index[length(index)]
if (sum(postseq[i1:i2])*seqstep <= 0.9){
cat("A 90% HPD interval is (",round(pseq[i1],4),",",round(pseq[i2],4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[i1:i2])*seqstep,3))
break
}
}
# HPD
for (j in seq(0.00001,1.5,by=0.00001)){
index <- which(postseq>=j)
i1 <- index[1]
i2 <- index[length(index)]
if (sum(postseq[i1:i2])*seqstep <= 0.9){
cat("A 90% HPD interval is (",round(pseq[i1],4),",",round(pseq[i2],4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[i1:i2])*seqstep,3))
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[ci1index:ci2index])*seqstep,3))
nseq=100000
pseq <- seq(0.001,4,length.out=nseq)
postseq <- post(pseq)
seqstep <- pseq[2]-pseq[1]
for (i in 1:(nseq/2)){
if (sum(postseq[1:(i+1)])*seqstep >= 0.05){
ci1index <- i+1
ci1 <- pseq[(i+1)]
break
}
}
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[ci1index:ci2index])*seqstep,3))
sum(postseq[1:ci1index])*seqstep
sum(postseq[ci1index:ci2index])*seqstep
sum(postseq[ci2index:nseq])*seqstep
sum(postseq[1:nseq])*seqstep
nseq=100000
pseq <- seq(0.001,5,length.out=nseq)
postseq <- post(pseq)
seqstep <- pseq[2]-pseq[1]
for (i in 1:(nseq/2)){
if (sum(postseq[1:(i+1)])*seqstep >= 0.05){
ci1index <- i+1
ci1 <- pseq[(i+1)]
break
}
}
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[ci1index:ci2index])*seqstep,3))
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[(ci1index+1):(ci2index+1)])*seqstep,3))
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[(ci1index+1):(ci2index-1)])*seqstep,3))
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[(ci1index+1):(ci2index-1)])*seqstep,3))
sum(postseq[(nseq-i):nseq])*seqstep
nseq=100000
pseq <- seq(0.001,5,length.out=nseq)
postseq <- post(pseq)
seqstep <- pseq[2]-pseq[1]
for (i in 1:(nseq/2)){
if (sum(postseq[1:(i+1)])*seqstep >= 0.05){
ci1index <- i+1
ci1 <- pseq[(i+1)]
break
}
}
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[(ci1index+1):(ci2index-1)])*seqstep,3))
sum(postseq[(1):nseq])*seqstep
sum(postseq[1:(ci1index)])*seqstep
sum(postseq[(ci2index):nseq])*seqstep
for (i in 1:(nseq/2)){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
for (i in 1:nseq){
if (sum(postseq[(nseq-i):nseq])*seqstep >= 0.05){
ci2index <- (nseq-i)
ci2 <- pseq[(nseq-i)]
break
}
}
cat("A 90% credible interval is (",round(ci1,4),",",round(ci2,4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[(ci1index+1):(ci2index-1)])*seqstep,3))
# HPD
for (j in seq(0.00001,1.5,by=0.00001)){
index <- which(postseq>=j)
i1 <- index[1]
i2 <- index[length(index)]
if (sum(postseq[i1:i2])*seqstep <= 0.9){
cat("A 90% HPD interval is (",round(pseq[i1],4),",",round(pseq[i2],4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[i1:i2])*seqstep,3))
break
}
}
ggplot() +
xlim(0, 3) +
geom_function(color = "blue", fun = post, n=1000) +
geom_vline(xintercept=pseq[i1], linetype="dashed", color = "red") +
geom_vline(xintercept=pseq[i2], linetype="dashed", color = "red") +
ylab("density") + xlab("") + ggtitle("90% HPD")
# HPD
for (j in seq(0.00001,1.5,by=0.00001)){
index <- which(postseq>=j)
i1 <- index[1]
i2 <- index[length(index)]
if (sum(postseq[i1:i2])*seqstep <= 0.9){
cat("A 90% HPD interval is (",round(pseq[i1],4),",",round(pseq[i2],4),") \n",
"Pr(theta in the interval) = ", round(sum(postseq[i1:i2])*seqstep,3))
break
}
}
boston_results
# Library
library(ggplot2)
# Input
Tmax <- 50 # Max number of pats
a0 <- 0.5 # Prior Pr(theta=0.4)=Pr(theta=0.6)=0.5
K <- 100 # Prespicified parameter in the utility function
############ Functions
# Function to select decision in each step
Deci <- function(c,p,t){
if (p < c*sqrt(t-1)/sqrt(Tmax-1)){
d <- 1
}else if (p <= ((c-1)*sqrt(t-1)/sqrt(Tmax-1) + 1) ){
d <- 0
}else{
d <- 2
}
return(d)
}
SimOne <- function(Tmax,c){
theta <- ifelse(runif(1)<a0,0.4,0.6)
y <- p <- d <-rep(NA,Tmax)
for (t in 1:(Tmax)){
# t \in 1,...,Tmax
N <- t
y[t] <- yt <- ifelse(runif(1)<theta,1,0)
p[t] <- pt <- mean(y[1:t])
d[t] <- dt <- Deci(c,pt,t)
if (!dt==0){
# Stop Trial
break
}
}
# utility
if ((theta == 0.4 & d[N] == 1)||(theta == 0.6 & d[N] == 2)){
u <- -N
}else{
u <- -N-K
}
onesim <- list(N=N, theta=theta, y=y, d=d, u=u)
return(onesim)
}
set.seed(123)
Nsim <- 5000
Ngrid <- 500
cgrid <- seq(0,1,length.out=Ngrid)
uest <- rep(NA,Ngrid)
# grid c
for (i in 1:Ngrid){
c <- cgrid[i]
u <- c()
for (k in 1:Nsim){
u <- c(u,SimOne(Tmax,c)$u)
}
uest[i] <- mean(u)
cat(i,"\t")
}
plotdata <- data.frame(cgrid=cgrid[2:(Ngrid-1)],uest=uest[2:(Ngrid-1)])
# Plot
ggplot(plotdata, aes(x=cgrid, y=uest)) +
geom_line()
ggsave("cgridrough.jpg")
ind_low <- which(cgrid>0.4)[1]
ind_high <- which(cgrid<0.6)[length(which(cgrid<0.6))]
## Linear regression
u_y <- uest[ind_low:ind_high]
cgrid_cut <- cgrid[ind_low:ind_high]
X <- cbind(cgrid_cut,cgrid_cut^2)
lm_coef <- lm(u_y ~ X)$coefficients
lm_coef
maxi <- -lm_coef[2]/lm_coef[3]/2
c_hat <- maxi
cat("Optimal c is", round(c_hat,3))
setwd("~/OneDrive - The University of Texas at Austin/Courses/Stats Modeling II/SDS383D_HW_YD")
# Set dimensions
p <- 2000
n <- 5000
# Generate data
beta <- rnorm(p,0,1)
# Set dimensions
p <- 2000
n <- 5000
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
y <- rep(0,n)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
library(matlib) # inv() function
library(matrixcalc) # LU decomposition
library(microbenchmark)
# Set dimensions
p <- 2000
n <- 5000
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
W <- diag(1,nrow=n,ncol=n)
y <- matrix(0,nrow=n,ncol=1)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
# function with inv()
invlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
beta_hat <- inv(A)%*%b
}
invlm(X,W,y)
install.packages("matlib")
install.packages("microbenchmark")
?microbenchmark
??microbenchmark
library(matlib) # inv() function
library(matrixcalc) # LU decomposition
library(microbenchmark)
# Set dimensions
p <- 2000
n <- 5000
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
W <- diag(1,nrow=n,ncol=n)
y <- matrix(0,nrow=n,ncol=1)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
# function with inv()
invlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
beta_hat <- inv(A)%*%b
return(beta_hat)
}
# function with LU decomposition
LUlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
# LU decomposition
decomp <- lu.decomposition(A)
L <- decomp$L
U <- decomp$U
y <- forwardsolve(L, b)
beta_hat <- backsolve(U, y)
return(beta_hat)
}
library(matlib) # inv() function
library(matrixcalc) # LU decomposition
library(microbenchmark)
# Set dimensions
p <- 200
n <- 500
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
W <- diag(1,nrow=n,ncol=n)
y <- matrix(0,nrow=n,ncol=1)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
# function with inv()
invlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
beta_hat <- inv(A)%*%b
return(beta_hat)
}
# function with LU decomposition
LUlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
# LU decomposition
decomp <- lu.decomposition(A)
L <- decomp$L
U <- decomp$U
y <- forwardsolve(L, b)
beta_hat <- backsolve(U, y)
return(beta_hat)
}
microbenchmark(invlm(X,W,y), LUlm(X,W,y))
microbenchmark(invlm(X,W,y), LUlm(X,W,y), times=10)
library(matlib) # inv() function
install.packages("matlib")
library(matlib) # inv() function
library(matlib) # inv() function
library(matrixcalc) # LU decomposition
library(microbenchmark)
# Set dimensions
p <- 200
n <- 500
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
W <- diag(1,nrow=n,ncol=n)
y <- matrix(0,nrow=n,ncol=1)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
# function with inv()
invlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
beta_hat <- solve(A)%*%b
return(beta_hat)
}
# function with LU decomposition
LUlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
# LU decomposition
decomp <- lu.decomposition(A)
L <- decomp$L
U <- decomp$U
y <- forwardsolve(L, b)
beta_hat <- backsolve(U, y)
return(beta_hat)
}
microbenchmark(invlm(X,W,y), LUlm(X,W,y), times=10)
library(matrixcalc) # LU decomposition
install.packages("matrixcalc")
library(matrixcalc) # LU decomposition
library(microbenchmark)
# Set dimensions
p <- 200
n <- 500
# Generate data
beta <- rnorm(p,0,1)
X <- matrix(0,nrow=n,ncol=p)
W <- diag(1,nrow=n,ncol=n)
y <- matrix(0,nrow=n,ncol=1)
for (i in 1:n){
X[i,] <- rnorm(p,0,1)
y[i] <- sum(X[i,]*beta) + rnorm(1,0,1) #1/sigma_i^2=1
}
# function with inv()
invlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
beta_hat <- solve(A)%*%b
return(beta_hat)
}
# function with LU decomposition
LUlm <- function(X,W,y){
A <- t(X)%*%W%*%X
b <- t(X)%*%W%*%y
# LU decomposition
decomp <- lu.decomposition(A)
L <- decomp$L
U <- decomp$U
y <- forwardsolve(L, b)
beta_hat <- backsolve(U, y)
return(beta_hat)
}
assign(paste0("out",i),microbenchmark(invlm(X,W,y), LUlm(X,W,y), times=10))
View(out500)
microbenchmark(invlm(X,W,y), LUlm(X,W,y), times=10)
library(matlib)
library(matlib) # inv() function
install.packages("rgl")
library(matlib) # inv() function
